#!/usr/bin/env python3
"""
Simple Integration Test - Tests core functionality without external dependencies.

This validates the enhanced system architecture works correctly.
"""

import asyncio
import sys
import os
from datetime import datetime

# Add the app directory to Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def test_imports():
    """Test that all enhanced components can be imported."""
    print("ğŸ”§ Testing Enhanced System Imports...")
    
    try:
        from app.enhanced_system_integration import EnhancedSlackBotSystem
        print("   âœ… Enhanced system integration")
        
        from app.services.enhanced_conversation_state_manager import EnhancedConversationStateManager
        print("   âœ… Conversation state manager")
        
        from app.workers.enhanced_message_processor import process_message_with_conversation_context_async
        print("   âœ… Enhanced message processor")
        
        from app.workers.enhanced_knowledge_extractor import EnhancedKnowledgeExtractor
        print("   âœ… Enhanced knowledge extractor")
        
        from app.workers.enhanced_query_processor import EnhancedQueryProcessor
        print("   âœ… Enhanced query processor")
        
        from app.testing.enhanced_testing_framework import EnhancedTestingFramework
        print("   âœ… Testing framework")
        
        from app.monitoring.quality_gates import QualityGatesSystem
        print("   âœ… Quality gates system")
        
        print("ğŸ‰ All imports successful!")
        return True
        
    except Exception as e:
        print(f"âŒ Import failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_system_initialization():
    """Test that enhanced system can be initialized."""
    print("\nğŸš€ Testing System Initialization...")
    
    try:
        from app.enhanced_system_integration import EnhancedSlackBotSystem
        
        system = EnhancedSlackBotSystem()
        print("   âœ… Enhanced SlackBot system initialized")
        
        # Check configuration
        config = system.config
        print(f"   âœ… System version: {config['version']}")
        print(f"   âœ… Features enabled: {sum(config['features_enabled'].values())}/{len(config['features_enabled'])}")
        
        # Check components
        print("   âœ… Conversation manager initialized")
        print("   âœ… Knowledge extractor initialized")
        print("   âœ… Query processor initialized")
        print("   âœ… Testing framework initialized")
        print("   âœ… Quality gates initialized")
        
        print("ğŸ‰ System initialization successful!")
        return True
        
    except Exception as e:
        print(f"âŒ System initialization failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_conversation_states():
    """Test conversation state enumeration."""
    print("\nğŸ”„ Testing Conversation States...")
    
    try:
        from app.services.enhanced_conversation_state_manager import ConversationState
        
        states = list(ConversationState)
        print(f"   âœ… Found {len(states)} conversation states:")
        
        for state in states:
            print(f"      â€¢ {state.value}")
        
        expected_states = ["initiated", "developing", "paused", "resolved", "abandoned"]
        for expected in expected_states:
            if any(state.value == expected for state in states):
                print(f"   âœ… {expected} state present")
            else:
                print(f"   âŒ {expected} state missing")
                return False
        
        print("ğŸ‰ Conversation states test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Conversation states test failed: {e}")
        return False

def test_knowledge_types():
    """Test knowledge extraction types."""
    print("\nğŸ§  Testing Knowledge Types...")
    
    try:
        from app.workers.enhanced_knowledge_extractor import EnhancedKnowledgeExtractor
        
        extractor = EnhancedKnowledgeExtractor()
        knowledge_types = extractor.knowledge_types
        
        print(f"   âœ… Found {len(knowledge_types)} knowledge types:")
        
        for k_type, config in knowledge_types.items():
            required_fields = len(config.get('required_fields', []))
            min_confidence = config.get('min_confidence', 0)
            print(f"      â€¢ {k_type}: {required_fields} fields, {min_confidence} min confidence")
        
        expected_types = ["technical_solution", "process_definition", "decision_made", 
                         "resource_recommendation", "troubleshooting_guide", "best_practice"]
        
        for expected in expected_types:
            if expected in knowledge_types:
                print(f"   âœ… {expected} type configured")
            else:
                print(f"   âŒ {expected} type missing")
                return False
        
        print("ğŸ‰ Knowledge types test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Knowledge types test failed: {e}")
        return False

def test_query_processing():
    """Test query processing components."""
    print("\nâ“ Testing Query Processing...")
    
    try:
        from app.workers.enhanced_query_processor import EnhancedQueryProcessor
        
        processor = EnhancedQueryProcessor()
        
        # Test intent patterns
        intent_patterns = processor.intent_patterns
        print(f"   âœ… Found {len(intent_patterns)} intent patterns:")
        
        for intent, patterns in intent_patterns.items():
            print(f"      â€¢ {intent}: {len(patterns)} patterns")
        
        # Test temporal indicators
        temporal_indicators = processor.temporal_indicators
        print(f"   âœ… Found {len(temporal_indicators)} temporal indicators")
        
        # Test configuration
        config = processor.config
        print(f"   âœ… Max search results: {config['max_search_results']}")
        print(f"   âœ… Min confidence threshold: {config['min_confidence_threshold']}")
        
        print("ğŸ‰ Query processing test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Query processing test failed: {e}")
        return False

def test_quality_gates():
    """Test quality gates configuration."""
    print("\nğŸšª Testing Quality Gates...")
    
    try:
        from app.monitoring.quality_gates import QualityGatesSystem
        
        quality_system = QualityGatesSystem()
        
        # Test production thresholds
        thresholds = quality_system.production_thresholds
        print(f"   âœ… Found {len(thresholds)} production thresholds:")
        
        key_thresholds = [
            "conversation_boundary_accuracy",
            "knowledge_extraction_precision", 
            "response_relevance_score",
            "user_satisfaction_score",
            "cost_per_query"
        ]
        
        for threshold in key_thresholds:
            if threshold in thresholds:
                value = thresholds[threshold]
                print(f"      â€¢ {threshold}: {value}")
            else:
                print(f"   âŒ Missing threshold: {threshold}")
                return False
        
        # Test monitoring configuration
        monitoring_config = quality_system.monitoring_config
        print(f"   âœ… Quality check interval: {monitoring_config['quality_check_interval_hours']} hours")
        
        print("ğŸ‰ Quality gates test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Quality gates test failed: {e}")
        return False

def test_database_schema():
    """Test enhanced database schema."""
    print("\nğŸ—„ï¸  Testing Database Schema...")
    
    try:
        from app.models.base import Conversation, Message, KnowledgeItem
        
        # Test Conversation model enhancements
        conversation_fields = [
            'state', 'state_confidence', 'state_updated_at',
            'participant_count', 'message_count', 'resolution_indicators',
            'is_ready_for_extraction', 'extraction_attempted_at', 'extraction_completed_at'
        ]
        
        for field in conversation_fields:
            if hasattr(Conversation, field):
                print(f"   âœ… Conversation.{field}")
            else:
                print(f"   âŒ Missing Conversation.{field}")
                return False
        
        # Test KnowledgeItem model
        knowledge_fields = ['knowledge_type', 'confidence_score', 'source_messages', 'participants']
        
        for field in knowledge_fields:
            if hasattr(KnowledgeItem, field):
                print(f"   âœ… KnowledgeItem.{field}")
            else:
                print(f"   âŒ Missing KnowledgeItem.{field}")
                return False
        
        print("ğŸ‰ Database schema test passed!")
        return True
        
    except Exception as e:
        print(f"âŒ Database schema test failed: {e}")
        return False

def run_all_tests():
    """Run all integration tests."""
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ENHANCED SLACKBOT INTEGRATION TESTS                       â•‘
â•‘                                                                              â•‘
â•‘  Testing Core Architecture Without External Dependencies                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Test Start Time: {datetime.utcnow().isoformat()}
""")
    
    tests = [
        ("Import Tests", test_imports),
        ("System Initialization", test_system_initialization),
        ("Conversation States", test_conversation_states),
        ("Knowledge Types", test_knowledge_types),
        ("Query Processing", test_query_processing),
        ("Quality Gates", test_quality_gates),
        ("Database Schema", test_database_schema)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    print(f"\n" + "="*80)
    print("INTEGRATION TEST SUMMARY")
    print("="*80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\nResults: {passed}/{total} tests passed ({passed/total:.1%})")
    
    for test_name, result in results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        print(f"   {status} {test_name}")
    
    overall_success = passed == total
    
    if overall_success:
        print(f"\nğŸ‰ ALL INTEGRATION TESTS PASSED!")
        print(f"   Enhanced SlackBot system architecture is working correctly")
        print(f"   Ready for database setup and end-to-end testing")
    else:
        print(f"\nâš ï¸  SOME TESTS FAILED")
        print(f"   Fix failing components before proceeding")
        print(f"   Check error messages above for details")
    
    print(f"\nğŸ”— Next Steps:")
    if overall_success:
        print(f"   1. Set up database connection (DATABASE_URL environment variable)")
        print(f"   2. Run database migrations: alembic upgrade head")
        print(f"   3. Run full end-to-end tests: python scripts/run_end_to_end_tests.py")
        print(f"   4. Deploy to staging: python scripts/deploy_enhanced_system.py staging")
    else:
        print(f"   1. Fix failing integration tests")
        print(f"   2. Re-run integration tests until all pass")
        print(f"   3. Then proceed with database setup")
    
    return overall_success

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
